{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import nltk\n",
        "\n",
        "from sklearn.tree imodel import LogisticRegression\n",
        "from sklearn.svm impomport DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.linear_rt SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# Download necessary NLTK data\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Set a fixed random seed\n",
        "import random\n",
        "random.seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "# Read data\n",
        "df = pd.read_csv('twitter_parsed_dataset.csv')\n",
        "df = pd.read_csv('twitter_parsed_dataset.csv')\n",
        "print(df.columns)\n",
        "# Preprocessing\n",
        "df = df[df['text'].apply(lambda x: isinstance(x, str))]  # Keep only rows where 'text' is a string\n",
        "df = df[df['label'].isin([0, 1])]  # Keep only rows where 'label' is 0 or 1\n",
        "df.drop_duplicates(inplace=True)\n",
        "\n",
        "# Convert to lowercase\n",
        "df['text'] = df['text'].apply(lambda x: x.lower())\n",
        "\n",
        "# Remove stopwords\n",
        "stop_words = set(stopwords.words('english'))\n",
        "df['text'] = df['text'].apply(lambda x: ' '.join([word for word in x.split() if word not in stop_words]))\n",
        "\n",
        "# Apply stemming\n",
        "ps = PorterStemmer()\n",
        "df['text'] = df['text'].apply(lambda x: ' '.join([ps.stem(word) for word in word_tokenize(x)]))\n",
        "\n",
        "# Oversampling\n",
        "ros = RandomOverSampler(random_state=0)\n",
        "x_resampled, y_resampled = ros.fit_resample(df[['text']], df['label'])\n",
        "\n",
        "# Convert resampled data back to pandas dataframes\n",
        "x_resampled = pd.DataFrame(x_resampled, columns=['text'])\n",
        "y_resampled = pd.Series(y_resampled, name='label')\n",
        "\n",
        "# Split the dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(x_resampled['text'], y_resampled, test_size=0.15, random_state=42)\n",
        "\n",
        "# Vectorization using TF-IDF\n",
        "vectorizer = TfidfVectorizer()\n",
        "X_train_vect = vectorizer.fit_transform(X_train)\n",
        "X_test_vect = vectorizer.transform(X_test)\n",
        "\n",
        "# Define base models\n",
        "base_model_1 = DecisionTreeClassifier(random_state=42)\n",
        "base_model_2 = KNeighborsClassifier()\n",
        "base_model_3 = GaussianNB()\n",
        "base_model_4 = LogisticRegression(random_state=42)\n",
        "base_model_5 = SVC(kernel='linear', random_state=42)\n",
        "\n",
        "# Train and evaluate each individual base model\n",
        "for i, base_model in enumerate([base_model_1, base_model_2, base_model_3, base_model_4, base_model_5], 1):\n",
        "    if isinstance(base_model, GaussianNB):\n",
        "        base_model.fit(X_train_vect.toarray(), y_train)\n",
        "        base_model_pred = base_model.predict(X_test_vect.toarray())\n",
        "    else:\n",
        "        base_model.fit(X_train_vect, y_train)\n",
        "        base_model_pred = base_model.predict(X_test_vect)\n",
        "    print(f'Accuracy of base model {i}: ', accuracy_score(y_test, base_model_pred))"
      ],
      "metadata": {
        "id": "rweRN0K1gnF9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Accuracy of base model 1:  0.9055346276441611\n",
        "\n",
        "Accuracy of base model 2:  0.8038249782671689\n",
        "\n",
        "Accuracy of base model 3:  0.744711677774558\n",
        "\n",
        "Accuracy of base model 4:  0.8753984352361635\n",
        "\n",
        "Accuracy of base model 5:  0.8930744711677775\n"
      ],
      "metadata": {
        "id": "gOoMpWyQgn98"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HZiQSu6LgYy2"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.ensemble import StackingClassifier\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# Download necessary NLTK data\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Set a fixed random seed\n",
        "import random\n",
        "random.seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "# Read data\n",
        "df = pd.read_csv('twitter_parsed_dataset.csv')\n",
        "\n",
        "# Preprocessing\n",
        "df = df[df['text'].apply(lambda x: isinstance(x, str))]  # Keep only rows where 'text' is a string\n",
        "df = df[df['label'].isin([0, 1])]  # Keep only rows where 'label' is 0 or 1\n",
        "df.drop_duplicates(inplace=True)\n",
        "\n",
        "# Convert to lowercase\n",
        "df['text'] = df['text'].apply(lambda x: x.lower())\n",
        "\n",
        "# Remove stopwords\n",
        "stop_words = set(stopwords.words('english'))\n",
        "df['text'] = df['text'].apply(lambda x: ' '.join([word for word in x.split() if word not in stop_words]))\n",
        "\n",
        "# Apply stemming\n",
        "ps = PorterStemmer()\n",
        "df['text'] = df['text'].apply(lambda x: ' '.join([ps.stem(word) for word in word_tokenize(x)]))\n",
        "\n",
        "# Oversampling\n",
        "ros = RandomOverSampler(random_state=0)\n",
        "x_resampled, y_resampled = ros.fit_resample(df[['text']], df['label'])\n",
        "\n",
        "# Convert resampled data back to pandas dataframes\n",
        "x_resampled = pd.DataFrame(x_resampled, columns=['text'])\n",
        "y_resampled = pd.Series(y_resampled, name='label')\n",
        "\n",
        "# Split the dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(x_resampled['text'], y_resampled, test_size=0.15, random_state=42)\n",
        "\n",
        "# Vectorization using TF-IDF\n",
        "vectorizer = TfidfVectorizer()\n",
        "X_train_vect = vectorizer.fit_transform(X_train)\n",
        "X_test_vect = vectorizer.transform(X_test)\n",
        "\n",
        "# Define base models\n",
        "base_models = [\n",
        "    (\"dt_model\", DecisionTreeClassifier(random_state=42)),\n",
        "    (\"knn_model\", KNeighborsClassifier(n_neighbors=5))\n",
        "]\n",
        "\n",
        "# Define StackingClassifier\n",
        "stacking_model = StackingClassifier(estimators=base_models, final_estimator=LogisticRegression(), cv=5)\n",
        "\n",
        "# Train the Stacking model\n",
        "stacking_model.fit(X_train_vect, y_train)\n",
        "\n",
        "# Predict the labels for the test data using the Stacking model\n",
        "stacking_pred = stacking_model.predict(X_test_vect)\n",
        "\n",
        "# Print the accuracy of the Stacking model\n",
        "print('Accuracy of Stacking model: ', accuracy_score(y_test, stacking_pred))\n",
        "\n",
        "# Print Stacking model metrics\n",
        "print(\"Stacking Model Precision: %.2f%%\" % (precision_score(y_test, stacking_pred) * 100))\n",
        "print(\"Stacking Model Recall: %.2f%%\" % (recall_score(y_test, stacking_pred) * 100))\n",
        "print(\"Stacking Model F1: %.2f%%\" % (f1_score(y_test, stacking_pred) * 100))\n",
        "print(\"Stacking Model ROC AUC: %.2f%%\" % (roc_auc_score(y_test, stacking_pred) * 100))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Accuracy of Stacking model:  0.9203129527673138\n",
        "\n",
        "Stacking Model Precision: 90.02%\n",
        "\n",
        "Stacking Model Recall: 94.22%\n",
        "\n",
        "Stacking Model F1: 92.07%\n",
        "\n",
        "Stacking Model ROC AUC: 92.07%"
      ],
      "metadata": {
        "id": "FhK7-vwAg2lz"
      }
    }
  ]
}